## LLM-NodeJS Dataset Description

The **LLM-NodeJS Dataset** is a collection of **50,000 unique Node.js JavaScript code samples** generated by 20 state-of-the-art Large Language Models (LLMs). Each LLM generated 2,500 samples based on prompts that required the creation of complex, realistic Node.js server-side scripts, for example: *"Create an API service that receives uploaded audio files and returns them converted to MP3 using FFmpeg integration."*. Only scripts that successfully passed the `node --check` syntax validation were included in the dataset. 

The LLM-NodeJS Dataset is used for JavaScript authorship attribution. We note that the diverse nature of the dataset makes it suitable for various types of research, such as malware analysis, code stylometry, and benchmarking for vulnerability detection in JavaScript code.


## Architecture Design

The framework for creating the LLM-NodeJS Dataset and performing JavaScript authorship attribution is illustrated in the figure below.

<img width="1693" height="683" alt="image" src="https://github.com/user-attachments/assets/0a204b90-7bd2-4ddb-8296-bab57f9689af" />

## Available Datasets

There are currently three types of datasets available: **LLM-NodeJS Small**, **LLM-NodeJS Medium**, and **LLM-NodeJS Large**.



### 1. LLM-NodeJS Small Dataset

This dataset is the smallest version and contains only the originally created 50,000 JavaScript samples. It does not include any JavaScript variants, such as obfuscated code. It is suitable for a wide range of research and, due to its compact size, is fast and easy to work with.

An example of a dataset entry is shown below:

```json
 {
    "model_name": "gpt-5-mini",
    "prompt": "Create a NodeJS application in JavaScript. Implicitly use strict mode and ES6 imports instead of require. Expect that all packages will be installed later, so no need for specifying how to install. Only return the javascirpt application between '```javascript' and '```' delimiters. The application is: Implement a CLI tool that monitors active network connections and logs when new IPs or ports appear.",
    "js_code": "<...JavaScript code...>",
    "SHA256_checksum": "0002afc1031410505c783c00f38041439b6d679ffd2808f727daa595cd02e02a",
    "char_count": 9973,
    "num_lines": 302
  }
```
[üìÇ Download LLM-NodeJS Small Dataset (ZIP)](https://github.com/LLM-NodeJS-dataset/LLM-NodeJS-dataset/releases/download/LLM-NodeJS-small/LLM-NodeJS-small.json.zip)

### 2. LLM-NodeJS Medium Dataset

This dataset includes four additional variants beyond the original JavaScript code. The original samples have been transformed into multiple formats to support research in areas such as malware analysis and LLM opcode stylometry for authorship attribution. The included categories are:

- **Simplified Script** ‚Äì Minimized using `rjsmin`, which removes comments and reduces file size while preserving functionality.  
- **Terser-Parsed and Mangled** ‚Äì Processed with **Terser**, where ‚Äúmangling‚Äù means renaming variables, functions, and parameters to short, non-descriptive names to reduce size and obfuscate readability.  
- **Obfuscated Version** ‚Äì Created with the `javascript-obfuscator` npm package to make the code significantly harder to read and reverse-engineer.  
- **Deobfuscated Version** ‚Äì Generated by applying the `deobfuscator` npm package to reverse the obfuscation and restore code readability.  

An example of a dataset entry is shown below:

```json
{
    "model_name": "gpt-oss-120b",
    "prompt": "Create a NodeJS application in JavaScript. Implicitly use strict mode and ES6 imports instead of require. Expect that all packages will be installed later, so no need for specifying how to install. Only return the javascirpt application between '```javascript' and '```' delimiters. The application is: Build an API that supports uploading and streaming MP4 videos with byte-range requests.",
    "js_original": {
      "js_code": "<...JavaScript code...>",
      "sha256_checksum": "a093cb8c01e65335d5b23be79c7a8247a32956e1eeae5aef1360aa811b0e1bc4",
      "char_count": 3063,
      "num_lines": 104,
      "token_count": 1223
    },
    "rjsmin_simplified": {
      "js_code": "<...JavaScript code...>",
      "sha256_checksum": "7ea47423db9661bd2eb1e1eb522ea06aa97f45349d1e3d4577623a0738cf1309",
      "char_count": 2200,
      "num_lines": 4,
      "token_count": 1079
    },
    "terser_mangled": {
      "js_code": "<...JavaScript code...>",
      "sha256_checksum": "930a49aa514760ca9aee71f45cae18c707904a259c7c8ca401a8cb73fbf258af",
      "char_count": 1760,
      "num_lines": 2,
      "token_count": 944
    },
    "js_obfuscated": {
      "js_code": "<...Obfuscated JavaScript code...>",
      "sha256_checksum": "18fc3d36fad31ec53f8620123f130cbe6180400fedb88dde66ba244e9f58dee0",
      "char_count": 7530,
      "num_lines": 1,
      "token_count": 5952
    },
    "js_deobfuscated": {
      "js_code": "<...Deobfuscated JavaScript code...>",
      "sha256_checksum": "2a1e9c24038b63772272132b8b27cf66c4a4b139aa2fa50d3401827e87bc0e5a",
      "char_count": 3298,
      "num_lines": 96,
      "token_count": 1753
    }
  },
```

[üìÇ Download LLM-NodeJS Medium Dataset (ZIP)](https://github.com/LLM-NodeJS-dataset/LLM-NodeJS-dataset/releases/download/LLM-NodeJS-medium/LLM-NodeJS-medium.json.zip)

### 3. LLM-NodeJS Large Dataset

This is the largest dataset, which contains two additional categories that can be useful for machine learning and malware analysis research. It includes all four categories from the medium dataset, plus two more, namely:

- **Abstract Syntax Tree (AST)** ‚Äì The structural representation of the JavaScript code, useful for program analysis and transformation.  
- **JSIR Representation** ‚Äì A high-level intermediate representation (IR) that leverages MLIR regions to accurately model control flow structures, used in Google‚Äôs JSIR tool for advanced JavaScript analysis.

The AST and JSIR representations are quite large for each JavaScript file, and the fully unzipped JSON dataset is around 20 GB. If you do not require these formats for your research, we strongly recommend using one of the smaller datasets.

[üìÇ Download LLM-NodeJS Large Dataset (ZIP)](https://github.com/LLM-NodeJS-dataset/LLM-NodeJS-dataset/releases/download/LLM-NodeJS-large/LLM-NodeJS-large.json.zip)

